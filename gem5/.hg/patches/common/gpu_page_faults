# HG changeset patch
# Parent deeba45fb1e5bd20f14c0c6074d893c4ec83ed48
Adds architectural changes required to handle GPU page faults.

This patch makes  changes:
 1) Adds a GPU page fault register to the CPU core. This is not architecturally
    visible. This register holds the state of the GPU page fault. Either
    0 => Not handling a GPU page fault, or 1 => currently handling a GPU page
    fault. This register is set by the GPU device MMU before raising a page
    fault interrupt.
 2) Modifies the iret instruction's microcode. Now, when returning from an
    interrupt, check the GPU page fault register. If the register is 1, then
    notify the GPU MMU that it's possible a GPU page fault has completed.
 3) Adds a gpufaultfinish psuedo-instruction and the microcode implementation.
    This instruction calls a function on the GPU, gpuFinishPageFault. This
    function is implemented in gem5-gpu.
* * *
Adds an interrupt to x86 that corresponds to a GPU page fault.
* * *
Update page fault interrupt to use shared_ptr
* * *
arch: Fix x86 GPU page fault interrupts

GPU page faults must be maskable interrupts, since they can only be raised when
the CPU thread is in user mode running the GPU application. Change the priority
of GPU page faults to be lower than unmaskable interrupts and only allow them
to be raised when the CPU thread is in user mode. Further, make sure that the
pendingGpu flag gets reset when a GPU page fault is started.
* * *
arch, x86: Add GPUPageFault fault type

One major problem with debugging GPU page fault handling is that there are few
points at which to do error checking. To provide more flexibility and
differentiate GPU page faults from regular page faults, add a thin shim
GPUPageFault type that allows modification of the constructor and invoke
functionality. This patch adds first-step error checking, and further patches
may add more status register handling/checking.
* * *
arch: GPU page faults: Add stack pointer verification

A CPU thread handling a GPU page fault can trigger numerous spurious callbacks
to the faulting GPU, leaving the ShaderMMU to check if a fault is complete
every time one of the callbacks occurs. This can lead to numerous fault
handling race conditions, corner cases, and unnecessary page walks.

To cut down on these spurious callbacks, track the CPU thread's stack pointer
from when it entered the kernel to handle the GPU page fault. Add a GPU fault
stack pointer register, and save this pointer when the page fault is invoked.
Check the pointer during IRET to decide whether to notify the GPU.

diff -r deeba45fb1e5 src/arch/x86/faults.hh
--- a/src/arch/x86/faults.hh	Fri Sep 04 17:59:16 2015 -0500
+++ b/src/arch/x86/faults.hh	Fri Sep 04 17:59:47 2015 -0500
@@ -45,6 +45,7 @@
 #include "arch/generic/tlb.hh"
 #include "base/bitunion.hh"
 #include "base/misc.hh"
+#include "debug/LocalApic.hh"
 #include "sim/faults.hh"
 
 namespace X86ISA
@@ -338,6 +339,53 @@
         virtual std::string describe() const;
     };
 
+    class GPUPageFault : public PageFault
+    {
+      public:
+        GPUPageFault(Addr _addr, uint32_t _errorCode) :
+            PageFault(_addr, _errorCode)
+        {
+            if (!((PageFaultErrorCode)errorCode).user) {
+                panic("GPU page faults can only be raised in user mode!");
+            }
+            faultName = "GPU Page Fault";
+        }
+
+        void invoke(ThreadContext * tc, const StaticInstPtr &inst =
+                    StaticInst::nullStaticInstPtr)
+        {
+            HandyM5Reg m5reg = tc->readMiscRegNoEffect(MISCREG_M5_REG);
+            if (m5reg.cpl != 3) {
+                // Unfortunately, we can't allow the GPU page fault to start
+                // here, because it is possible that the OS will not have the
+                // GPU application's pagetable in the CR3, so handling the
+                // fault would likely result in a segmentation fault.
+                warn("Invoking GPU page fault in kernel mode!\n");
+            }
+
+            GPUFaultReg fault_reg = tc->readMiscRegNoEffect(MISCREG_GPU_FAULT);
+            // Verify that the fault is still in flight. If not, either the
+            // ShaderMMU dropped the fault for some reason, or the GPU
+            // application thread (and fault_reg) may have been migrated from
+            // the passed thread context (i.e. a bad situation).
+            assert(fault_reg.inFault == 1);
+            GPUFaultRSPReg fault_rsp =
+                    tc->readMiscRegNoEffect(MISCREG_GPU_FAULT_RSP);
+            assert(fault_rsp == 0);
+
+            PageFault::invoke(tc, inst);
+
+            // Change inFault to indicate that the fault handler has been
+            // invoked and will be running
+            fault_reg.inFault = 2;
+            tc->setMiscRegActuallyNoEffect(MISCREG_GPU_FAULT, fault_reg);
+            fault_rsp = tc->readIntReg(INTREG_RSP);
+            DPRINTF(LocalApic,
+                    "Invoking GPU page fault interrupt. SP: %x\n", fault_rsp);
+            tc->setMiscRegActuallyNoEffect(MISCREG_GPU_FAULT_RSP, fault_rsp);
+        }
+    };
+
     class X87FpExceptionPending : public X86Fault
     {
       public:
diff -r deeba45fb1e5 src/arch/x86/interrupts.cc
--- a/src/arch/x86/interrupts.cc	Fri Sep 04 17:59:16 2015 -0500
+++ b/src/arch/x86/interrupts.cc	Fri Sep 04 17:59:47 2015 -0500
@@ -271,7 +271,10 @@
     } else if (!DeliveryMode::isReserved(deliveryMode)) {
         DPRINTF(LocalApic, "Interrupt is an %s.\n",
                 DeliveryMode::names[deliveryMode]);
-        if (deliveryMode == DeliveryMode::SMI && !pendingSmi) {
+        if (deliveryMode == DeliveryMode::GPUFault) {
+            assert(!pendingGpu);
+            pendingGpu = true;
+        } else if (deliveryMode == DeliveryMode::SMI && !pendingSmi) {
             pendingUnmaskableInt = pendingSmi = true;
             smiVector = vector;
         } else if (deliveryMode == DeliveryMode::NMI && !pendingNmi) {
@@ -611,7 +614,7 @@
 
 X86ISA::Interrupts::Interrupts(Params * p)
     : BasicPioDevice(p, PageBytes), IntDevice(this, p->int_latency),
-      apicTimerEvent(this),
+      apicTimerEvent(this), pendingGpu(false),
       pendingSmi(false), smiVector(0),
       pendingNmi(false), nmiVector(0),
       pendingExtInt(false), extIntVector(0),
@@ -642,6 +645,14 @@
             DPRINTF(LocalApic, "Reported pending external interrupt.\n");
             return true;
         }
+        if (pendingGpu) {
+            HandyM5Reg m5reg = tc->readMiscRegNoEffect(MISCREG_M5_REG);
+            if (m5reg.cpl != 3) {
+                DPRINTF(LocalApic, "Not invoking GPU PF in kernel mode!\n");
+            } else {
+                return true;
+            }
+        }
         if (IRRV > ISRV && bits(IRRV, 7, 4) >
                bits(regs[APIC_TASK_PRIORITY], 7, 4)) {
             DPRINTF(LocalApic, "Reported pending regular interrupt.\n");
@@ -663,6 +674,8 @@
 X86ISA::Interrupts::getInterrupt(ThreadContext *tc)
 {
     assert(checkInterrupts(tc));
+    RFLAGS rflags = tc->readMiscRegNoEffect(MISCREG_RFLAGS);
+    HandyM5Reg m5reg = tc->readMiscRegNoEffect(MISCREG_M5_REG);
     // These are all probably fairly uncommon, so we'll make them easier to
     // check for.
     if (pendingUnmaskableInt) {
@@ -686,6 +699,15 @@
     } else if (pendingExtInt) {
         DPRINTF(LocalApic, "Generated external interrupt fault object.\n");
         return std::make_shared<ExternalInterrupt>(extIntVector);
+    } else if (pendingGpu && rflags.intf && m5reg.cpl == 3) {
+        DPRINTF(LocalApic, "Generated GPU page fault object.\n");
+        Addr addr = tc->readMiscRegNoEffect(MISCREG_GPU_FAULTADDR);
+        uint32_t code = tc->readMiscRegNoEffect(MISCREG_GPU_FAULTCODE);
+        if (((GPUFaultReg)tc->readMiscRegNoEffect(MISCREG_GPU_FAULT)).inFault != 1) {
+            panic("Need to migrate the miscellaneous registers?! tc = %p, inFault: %d\n",
+                  tc, ((GPUFaultReg)tc->readMiscRegNoEffect(MISCREG_GPU_FAULT)).inFault);
+        }
+        return std::make_shared<GPUPageFault>(addr, code);
     } else {
         DPRINTF(LocalApic, "Generated regular interrupt fault object.\n");
         // The only thing left are fixed and lowest priority interrupts.
@@ -697,6 +719,8 @@
 X86ISA::Interrupts::updateIntrInfo(ThreadContext *tc)
 {
     assert(checkInterrupts(tc));
+    RFLAGS rflags = tc->readMiscRegNoEffect(MISCREG_RFLAGS);
+    HandyM5Reg m5reg = tc->readMiscRegNoEffect(MISCREG_M5_REG);
     if (pendingUnmaskableInt) {
         if (pendingSmi) {
             DPRINTF(LocalApic, "SMI sent to core.\n");
@@ -717,6 +741,8 @@
             pendingUnmaskableInt = false;
     } else if (pendingExtInt) {
         pendingExtInt = false;
+    } else if (pendingGpu && rflags.intf && m5reg.cpl == 3) {
+        pendingGpu = false;
     } else {
         DPRINTF(LocalApic, "Interrupt %d sent to core.\n", IRRV);
         // Mark the interrupt as "in service".
diff -r deeba45fb1e5 src/arch/x86/interrupts.hh
--- a/src/arch/x86/interrupts.hh	Fri Sep 04 17:59:16 2015 -0500
+++ b/src/arch/x86/interrupts.hh	Fri Sep 04 17:59:47 2015 -0500
@@ -117,6 +117,7 @@
      * A set of variables to keep track of interrupts that don't go through
      * the IRR.
      */
+    bool pendingGpu;
     bool pendingSmi;
     uint8_t smiVector;
     bool pendingNmi;
@@ -231,6 +232,12 @@
         return entry.periodic;
     }
 
+    void
+    triggerGPUInterrupt()
+    {
+        requestInterrupt(0, DeliveryMode::GPUFault, false);
+    }
+
     AddrRangeList getIntAddrRange() const;
 
     BaseMasterPort &getMasterPort(const std::string &if_name,
diff -r deeba45fb1e5 src/arch/x86/intmessage.hh
--- a/src/arch/x86/intmessage.hh	Fri Sep 04 17:59:16 2015 -0500
+++ b/src/arch/x86/intmessage.hh	Fri Sep 04 17:59:47 2015 -0500
@@ -59,12 +59,13 @@
             INIT = 5,
             SIPI = 6,
             ExtInt = 7,
+            GPUFault = 8,
             NumModes
         };
 
         static const char * const names[NumModes] = {
             "Fixed", "LowestPriority", "SMI", "Reserved",
-            "NMI", "INIT", "Startup", "ExtInt"
+            "NMI", "INIT", "Startup", "ExtInt", "GPUFault"
         };
 
         static inline bool
diff -r deeba45fb1e5 src/arch/x86/isa/insts/general_purpose/control_transfer/interrupts_and_exceptions.py
--- a/src/arch/x86/isa/insts/general_purpose/control_transfer/interrupts_and_exceptions.py	Fri Sep 04 17:59:16 2015 -0500
+++ b/src/arch/x86/isa/insts/general_purpose/control_transfer/interrupts_and_exceptions.py	Fri Sep 04 17:59:47 2015 -0500
@@ -137,6 +137,13 @@
     br label("doPopStackStuff"), flags=(nCEZF,)
     # We can modify user visible state here because we're know
     # we're done with things that can fault.
+
+    # gem5-gpu: Grab the old return stack pointer into t6, then pop the
+    # old stack. Must save the stack pointer to ensure the thread knows
+    # precisely when it needs to to notify the GPU. Do this before popping
+    # the stack pointer!
+    ld t6, ss, [1, t0, rsp], "3 * env.dataSize", dataSize=ssz
+
     addi rsp, rsp, "3 * env.stackSize"
     br label("fallThroughPopStackStuff")
 
@@ -206,6 +213,20 @@
 
 skipSegmentSquashing:
 
+    # Check if this was a GPU fault and if so, notify the GPU.
+    rdval t5, "InstRegIndex(MISCREG_GPU_FAULT)"
+    andi t0, t5, 2, flags=(EZF,)
+    br label("notGPUFaultFallThrough"), flags=(CEZF,)
+    # At this point, t6 *should* contain the old stack pointer from where the
+    # fault was raised, no matter how the microcode reached this GPU check. If
+    # t6 is equal to the GPU faulting RSP, notify the GPU of finished fault!
+    rdval t5, "InstRegIndex(MISCREG_GPU_FAULT_RSP)"
+    xor t5, t5, t6, flags=(EZF,)
+    br label("notGPUFaultFallThrough"), flags=(nCEZF,)
+    gpufaultfinish
+
+notGPUFaultFallThrough:
+
     # Ignore this for now.
     #RFLAGS.v = temp_RFLAGS
     wrflags t0, t3
diff -r deeba45fb1e5 src/arch/x86/isa/microops/gpu.isa
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/arch/x86/isa/microops/gpu.isa	Fri Sep 04 17:59:47 2015 -0500
@@ -0,0 +1,91 @@
+// Copyright (c) 2013 Mark D. Hill and David A. Wood
+// All rights reserved.
+//
+// The license below extends only to copyright in the software and shall
+// not be construed as granting a license to any other intellectual
+// property including but not limited to intellectual property relating
+// to a hardware implementation of the functionality of the software
+// licensed hereunder.  You may use the software subject to the license
+// terms below provided that you ensure that this notice is replicated
+// unmodified and in its entirety in all distributions of the software,
+// modified or unmodified, in source code or in binary form.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are
+// met: redistributions of source code must retain the above copyright
+// notice, this list of conditions and the following disclaimer;
+// redistributions in binary form must reproduce the above copyright
+// notice, this list of conditions and the following disclaimer in the
+// documentation and/or other materials provided with the distribution;
+// neither the name of the copyright holders nor the names of its
+// contributors may be used to endorse or promote products derived from
+// this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// Authors: Jason Power
+
+output header {{
+        void gpuFinishPageFault(int gpuId, ThreadContext *tc);
+    class GPUFaultFinish : public X86ISA::X86MicroopBase
+    {
+      public:
+        GPUFaultFinish(ExtMachInst _machInst, const char * instMnem,
+                uint64_t setFlags) :
+            X86MicroopBase(_machInst, "gpufaultfinish", instMnem,
+                           setFlags | (ULL(1) << StaticInst::IsNonSpeculative),
+                           No_OpClass)
+        {
+        }
+
+        %(BasicExecDeclare)s
+
+        std::string generateDisassembly(Addr pc,
+                const SymbolTable *symtab) const;
+    };
+}};
+
+output exec {{
+    Fault
+    GPUFaultFinish::execute(CPU_EXEC_CONTEXT *xc,
+            Trace::InstRecord * traceData) const
+    {
+        gpuFinishPageFault(0, xc->tcBase());
+        return NoFault;
+    }
+}};
+
+output decoder {{
+    std::string GPUFaultFinish::generateDisassembly(Addr pc,
+            const SymbolTable *symtab) const
+    {
+        std::stringstream response;
+
+        printMnemonic(response, instMnem, mnemonic);
+
+        return response.str();
+    }
+}};
+
+let {{
+    class GPUFaultFinish(X86Microop):
+        className = "GPUFaultFinish"
+        def __init__(self):
+            pass
+
+        def getAllocator(self, microFlags):
+            return "new GPUFaultFinish(machInst, macrocodeBlock, %s)" % \
+                    self.microFlagsText(microFlags)
+
+    microopClasses["gpufaultfinish"] = GPUFaultFinish
+}};
diff -r deeba45fb1e5 src/arch/x86/isa/microops/microops.isa
--- a/src/arch/x86/isa/microops/microops.isa	Fri Sep 04 17:59:16 2015 -0500
+++ b/src/arch/x86/isa/microops/microops.isa	Fri Sep 04 17:59:47 2015 -0500
@@ -61,3 +61,6 @@
 
 //Microops for printing out debug messages through M5
 ##include "debug.isa"
+
+//Microops for interacting with the GPU
+##include "gpu.isa"
diff -r deeba45fb1e5 src/arch/x86/regs/misc.hh
--- a/src/arch/x86/regs/misc.hh	Fri Sep 04 17:59:16 2015 -0500
+++ b/src/arch/x86/regs/misc.hh	Fri Sep 04 17:59:47 2015 -0500
@@ -396,6 +396,12 @@
         // "Fake" MSRs for internally implemented devices
         MISCREG_PCI_CONFIG_ADDRESS,
 
+        // GPU fault register
+        MISCREG_GPU_FAULT,
+        MISCREG_GPU_FAULTADDR,
+        MISCREG_GPU_FAULTCODE,
+        MISCREG_GPU_FAULT_RSP,
+
         NUM_MISCREGS
     };
 
@@ -995,6 +1001,25 @@
         Bitfield<11> enable;
         Bitfield<8> bsp;
     EndBitUnion(LocalApicBase)
+
+    /**
+     * Register for active GPU page fault
+     * May need to increase to more bits if more than 1 GPU is in the system
+     */
+    BitUnion64(GPUFaultReg)
+        Bitfield<1, 0> inFault;
+    EndBitUnion(GPUFaultReg)
+
+    BitUnion64(GPUFaultCode)
+        Bitfield<0> present;
+        Bitfield<1> write;
+        Bitfield<2> user;
+        Bitfield<3> reserved;
+        Bitfield<4> fetch;
+    EndBitUnion(GPUFaultCode)
+
+    BitUnion64(GPUFaultRSPReg)
+    EndBitUnion(GPUFaultRSPReg)
 }
 
 #endif // __ARCH_X86_INTREGS_HH__
